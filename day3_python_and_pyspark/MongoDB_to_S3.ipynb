{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#import pyspark & urllib"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6d23e9de-a8d1-4149-aaa7-a70b8ad89f80","showTitle":false,"title":""}},"outputs":[],"source":["# ======= Read from MongoDB ========\n","\n","#define the fromat which is in our case \"com.mongodb.spark.sql.DefaultSource\", define the database name [sample_mflix] and the collection name [users]\n","users_tbl = spark.read.format().option().option().load()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c1f6c133-041f-4fa0-98fe-0af7215583c8","showTitle":false,"title":""}},"outputs":[],"source":["# show the table\n","users_tbl.show(truncate = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"90a6038e-a4e7-4a2e-b722-9084b2ee158b","showTitle":false,"title":""}},"outputs":[],"source":["# take sample of the pyspark df\n","users_tbl = \n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"90318c04-48b4-42cc-b8e9-dfdf1cb68d24","showTitle":false,"title":""}},"outputs":[],"source":["# drop the _id column\n","users_tbl = "]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b1543fd7-4dba-4f89-a108-d8e107a95f31","showTitle":false,"title":""}},"outputs":[],"source":["# ======= Write to S3 ========\n","\n","# mount S3, change the ACCESS_KEY, secret_key & AwsBucketName.\n","ACCESS_KEY = \"xx\"\n","secret_key = \"xx\"\n","AwsBucketName = \"xxxx\"\n","MountName = \"/mnt/MOUNT-xxx\"\n","ENCODED_SECRET_KEY = urllib.parse.quote(string=secret_key, safe=\"\")\n","SOURCE_URL = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AwsBucketName) \n","\n","dbutils.fs.mount(SOURCE_URL, MountName)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"0c48406b-cc6a-474e-8e51-7c5325ca76fb","showTitle":false,"title":""}},"outputs":[],"source":["#wirte to s3 using write.save as csv format\n","users_tbl.write."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6d2d7a79-f200-4f53-a354-45cd7f5d55a5","showTitle":false,"title":""}},"outputs":[],"source":["# validate the writing process \n","df = spark.read.format().load(, header = True)\n","\n","df.show()"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"MongoDB_to_S3","notebookOrigID":1697531984647853,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
